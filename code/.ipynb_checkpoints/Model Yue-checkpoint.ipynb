{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape: (4559, 512)\n",
      "X2.shape: (4559, 30000)\n",
      "y1.shape: (4559,)\n",
      "y2.shape: (4559,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X1 = pd.read_csv('../data/features.csv', header=None).values\n",
    "X2 = pd.read_csv('../data/raw_images.csv', header=None).values\n",
    "y1 = pd.read_csv('../data/labels.csv', header=None).values.ravel().astype(int)\n",
    "y2 = pd.read_csv('../data/labels.csv', header=None).values.ravel().astype(int)\n",
    "\n",
    "print('X1.shape:', X1.shape)\n",
    "print('X2.shape:', X2.shape)\n",
    "print('y1.shape:', y1.shape)\n",
    "print('y2.shape:', y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 3191 639 1368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = \\\n",
    "    train_test_split(X1, y1, test_size=0.3, random_state=123, shuffle=True, stratify=y1)\n",
    "\n",
    "X1_train_sub, X1_valid, y1_train_sub, y1_valid = \\\n",
    "    train_test_split(X1_train, y1_train, test_size=0.2, random_state=123, stratify=y1_train)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y1_train.shape[0], y1_valid.shape[0], y1_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 3191 639 1368\n"
     ]
    }
   ],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = \\\n",
    "    train_test_split(X2, y2, test_size=0.3, random_state=123, shuffle=True, stratify=y2)\n",
    "\n",
    "X2_train_sub, X2_valid, y2_train_sub, y2_valid = \\\n",
    "    train_test_split(X2_train, y2_train, test_size=0.2, random_state=123, stratify=y2_train)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y2_train.shape[0], y2_valid.shape[0], y2_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   2.8s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   2.7s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   2.8s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   3.1s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   3.0s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.2s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.3s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.3s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.2s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.1s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.4s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.4s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.1s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.8s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.6s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.7s\n",
      "[22:49:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.4s\n",
      "[22:50:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.4s\n",
      "[22:50:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.3s\n",
      "[22:50:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.3s\n",
      "[22:50:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.3s\n",
      "[22:50:06] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.3s\n",
      "[22:50:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.4s\n",
      "[22:50:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.4s\n",
      "[22:50:10] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.4s\n",
      "[22:50:12] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.3s\n",
      "[22:50:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.2s\n",
      "[22:50:15] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.3s\n",
      "[22:50:17] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.3s\n",
      "[22:50:20] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.2s\n",
      "[22:50:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.3s\n",
      "[22:50:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.3s\n",
      "[22:50:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.1s\n",
      "[22:50:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[22:50:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[22:50:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.2s\n",
      "[22:50:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[22:50:48] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  17.9s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  18.1s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  16.9s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  19.0s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  17.1s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   5.0s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   5.3s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   4.7s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   4.6s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   5.1s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  11.7s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  12.4s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  12.2s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  11.6s\n",
      "[22:53:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.3s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.3s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.2s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.2s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9197712923307872"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(random_state=123, use_label_encoder=False)\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[30, 50, 100, 300, 500],\n",
    "    'min_child_weight':[4,5], \n",
    "    \"reg_lambda\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    \"alpha\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "search1 = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search1.fit(X1_train, y1_train)\n",
    "\n",
    "search1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.6917018087001772,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bytree': 0.7,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'rmse',\n",
       " 'gamma': 0.3,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 100,\n",
       " 'objective': 'reg:tweedie',\n",
       " 'reg_lambda': 0.029423743551983135,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  99.94%\n",
      "Test Accuracy:  91.74%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search1.best_estimator_.score(X1_train, y1_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search1.best_estimator_.score(X1_test, y1_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9170036919863896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, search1.best_estimator_.predict(X1_test), average='weighted')}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 1/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.930 total time= 3.3min\n",
      "[CV 2/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 2/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.936 total time= 3.0min\n",
      "[CV 3/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 3/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.951 total time= 3.0min\n",
      "[CV 4/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 4/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.937 total time= 3.0min\n",
      "[CV 5/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 5/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.953 total time= 3.0min\n",
      "[CV 1/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 1/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.933 total time= 1.1min\n",
      "[CV 2/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 2/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.937 total time= 1.1min\n",
      "[CV 3/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 3/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.945 total time= 1.1min\n",
      "[CV 4/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 4/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.926 total time= 1.1min\n",
      "[CV 5/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 5/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.953 total time= 1.1min\n",
      "[CV 1/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 1/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.933 total time= 1.2min\n",
      "[CV 2/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 2/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.937 total time= 1.2min\n",
      "[CV 3/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 3/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.950 total time= 1.2min\n",
      "[CV 4/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 4/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.931 total time= 1.2min\n",
      "[CV 5/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 5/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.959 total time= 1.2min\n",
      "[CV 1/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 1/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.937 total time= 2.9min\n",
      "[CV 2/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.937 total time= 2.8min\n",
      "[CV 3/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 3/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.948 total time= 2.9min\n",
      "[CV 4/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 4/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.928 total time= 2.8min\n",
      "[CV 5/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 5/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.950 total time= 3.0min\n",
      "[CV 1/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:34:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.928 total time= 2.3min\n",
      "[CV 2/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:36:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.915 total time= 2.2min\n",
      "[CV 3/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:38:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.936 total time= 2.1min\n",
      "[CV 4/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:40:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.923 total time= 2.2min\n",
      "[CV 5/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:42:53] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.931 total time= 2.2min\n",
      "[CV 1/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:45:06] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.942 total time= 2.5min\n",
      "[CV 2/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:47:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.925 total time= 2.5min\n",
      "[CV 3/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:50:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.940 total time= 2.4min\n",
      "[CV 4/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:52:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.928 total time= 2.4min\n",
      "[CV 5/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:54:57] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.931 total time= 2.4min\n",
      "[CV 1/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[00:57:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.944 total time= 4.6min\n",
      "[CV 2/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:01:55] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.925 total time= 4.6min\n",
      "[CV 3/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:06:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.936 total time= 4.6min\n",
      "[CV 4/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:11:12] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.929 total time= 4.6min\n",
      "[CV 5/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:15:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.929 total time= 4.5min\n",
      "[CV 1/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:20:16] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.934 total time= 2.2min\n",
      "[CV 2/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:22:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.918 total time= 2.2min\n",
      "[CV 3/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:24:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.936 total time= 2.1min\n",
      "[CV 4/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:26:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.925 total time= 2.1min\n",
      "[CV 5/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:28:51] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.931 total time= 2.1min\n",
      "[CV 1/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:31:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.950 total time= 2.8min\n",
      "[CV 2/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:33:48] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.925 total time= 2.9min\n",
      "[CV 3/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:36:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.940 total time= 2.8min\n",
      "[CV 4/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:39:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.934 total time= 2.8min\n",
      "[CV 5/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:42:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.937 total time= 2.8min\n",
      "[CV 1/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.953 total time=  11.9s\n",
      "[CV 2/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.929 total time=  11.9s\n",
      "[CV 3/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.945 total time=  11.8s\n",
      "[CV 4/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:49] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.936 total time=  11.8s\n",
      "[CV 5/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:46:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.947 total time=  11.8s\n",
      "[CV 1/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[01:46:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.931 total time= 3.5min\n",
      "[CV 2/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[01:49:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.920 total time= 4.3min\n",
      "[CV 3/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:54:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.936 total time= 3.9min\n",
      "[CV 4/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[01:57:53] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.925 total time= 3.6min\n",
      "[CV 5/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[02:01:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.929 total time= 3.6min\n",
      "[CV 1/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 1/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.933 total time=11.8min\n",
      "[CV 2/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 2/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.936 total time=12.1min\n",
      "[CV 3/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 3/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.950 total time=11.7min\n",
      "[CV 4/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 4/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.939 total time=11.6min\n",
      "[CV 5/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 5/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.956 total time=12.0min\n",
      "[CV 1/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 1/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.937 total time= 3.5min\n",
      "[CV 2/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 2/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.929 total time= 3.4min\n",
      "[CV 3/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 3/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.948 total time= 3.4min\n",
      "[CV 4/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 4/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.937 total time= 3.3min\n",
      "[CV 5/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 5/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.959 total time= 3.5min\n",
      "[CV 1/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.936 total time= 8.1min\n",
      "[CV 2/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 2/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.933 total time= 8.3min\n",
      "[CV 3/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 3/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.950 total time= 8.4min\n",
      "[CV 4/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 4/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.934 total time= 8.0min\n",
      "[CV 5/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 5/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.950 total time= 8.1min\n",
      "[CV 1/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:02:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.948 total time=  16.6s\n",
      "[CV 2/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:02:45] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.929 total time=  16.7s\n",
      "[CV 3/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:03:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.947 total time=  16.8s\n",
      "[CV 4/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:03:19] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.934 total time=  16.7s\n",
      "[CV 5/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:03:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.940 total time=  16.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94265432371309"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[30, 50, 100, 300, 500],\n",
    "    'min_child_weight':[4,5], \n",
    "    \"reg_lambda\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    \"alpha\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "search2 = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=10,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search2.fit(X2_train, y2_train)\n",
    "\n",
    "search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.3929444207680876,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bytree': 1.0,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'rmse',\n",
       " 'gamma': 0.5,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'reg_lambda': 0.0576480249714419,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  100.00%\n",
      "Test Accuracy:  94.88%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search2.best_estimator_.score(X2_train, y2_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search2.best_estimator_.score(X2_test, y2_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9487152602563024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y2_test, search2.best_estimator_.predict(X2_test), average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[431,  10,   2],\n",
       "       [ 19, 422,   3],\n",
       "       [ 18,  18, 445]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "xgb_cm_true = contingency_matrix(search2.best_estimator_.predict(X2_test), y2_test)\n",
    "xgb_cm_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=xgb_cm_true,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True,\n",
    "                                colorbar=True,\n",
    "                                figsize=(3, 3))\n",
    "plt.savefig(\"xgb_cm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.759635579937304"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=123, max_iter = 1000)\n",
    "\n",
    "params = {\n",
    "    \"C\": scipy.stats.expon(scale=.01),\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"warm_start\": [True,False]\n",
    "}\n",
    "\n",
    "search3 = RandomizedSearchCV(\n",
    "    estimator=lr,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=10,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search3.fit(X1_train, y1_train)\n",
    "\n",
    "search3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.03950982068814718, 'fit_intercept': True, 'warm_start': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  76.68%\n",
      "Test Accuracy:  78.22%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search3.best_estimator_.score(X1_train, y1_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search3.best_estimator_.score(X1_test, y1_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7691277689909498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, search3.best_estimator_.predict(X1_test), average='weighted')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.9min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.8min\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.4min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.3min\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.4min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9288631825785784"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search4 = RandomizedSearchCV(\n",
    "    estimator=lr,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search4.fit(X2_train, y2_train)\n",
    "\n",
    "search4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.002572840801170508, 'fit_intercept': True, 'warm_start': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  100.00%\n",
      "Test Accuracy:  93.20%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search4.best_estimator_.score(X2_train, y2_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search4.best_estimator_.score(X2_test, y2_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.931976655005432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y2_test, search4.best_estimator_.predict(X2_test), average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[430,  17,   8],\n",
       "       [ 25, 415,  12],\n",
       "       [ 13,  18, 430]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "lr_cm_true = contingency_matrix(search4.best_estimator_.predict(X2_test), y2_test)\n",
    "lr_cm_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=lr_cm_true,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True,\n",
    "                                colorbar=True,\n",
    "                                figsize=(3, 3))\n",
    "plt.savefig(\"lr_cm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree + Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8691232109282069"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "params =  {\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'max_depth': [5, 7, 9, 11, None],\n",
    "    'criterion':['entropy', 'gini']\n",
    "}\n",
    "\n",
    "search5 = RandomizedSearchCV(\n",
    "    estimator=tree,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search5.fit(X1_train_sub, y1_train_sub)\n",
    "\n",
    "search5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 3, 'max_depth': 5, 'criterion': 'gini'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  91.77%\n",
      "Valid Accuracy:  87.32%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search5.best_estimator_.score(X1_train_sub, y1_train_sub)*100: 0.2f}%\") \n",
    "print(f\"Valid Accuracy: {search5.best_estimator_.score(X1_valid, y1_valid)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 93.06%\n",
      "Valid Accuracy: 88.58%\n",
      "Test Accuracy: 89.18%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag1 = BaggingClassifier(base_estimator=search5.best_estimator_, \n",
    "                        n_estimators=150, \n",
    "                        oob_score=True, \n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False, \n",
    "                        n_jobs=1, \n",
    "                        random_state=123)\n",
    "\n",
    "bag1.fit(X1_train_sub, y1_train_sub)\n",
    "print(f\"Train Accuracy: {bag1.score(X1_train_sub, y1_train_sub)*100:0.2f}%\")\n",
    "print(f\"Valid Accuracy: {bag1.score(X1_valid, y1_valid)*100:0.2f}%\")\n",
    "print(f\"Test Accuracy: {bag1.score(X1_test, y1_test)*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8912916961773778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, bag1.predict(X1_test), average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "search6 = DecisionTreeClassifier(max_depth=4, \n",
    "                                 min_impurity_decrease=0.011493972900871952,\n",
    "                                 min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 91.77%\n",
      "Valid Accuracy: 90.30%\n",
      "Test Accuracy: 91.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag2 = BaggingClassifier(base_estimator=search6, \n",
    "                        n_estimators=50, \n",
    "                        oob_score=True, \n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False, \n",
    "                        n_jobs=1, \n",
    "                        random_state=123)\n",
    "\n",
    "bag2.fit(X2_train_sub, y2_train_sub)\n",
    "print(f\"Train Accuracy: {bag2.score(X2_train_sub, y2_train_sub)*100:0.2f}%\")\n",
    "print(f\"Valid Accuracy: {bag2.score(X2_valid, y2_valid)*100:0.2f}%\")\n",
    "print(f\"Test Accuracy: {bag2.score(X2_test, y2_test)*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9121410382503217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y2_test, bag2.predict(X2_test), average='weighted')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[418,  22,   8],\n",
       "       [ 22, 399,  11],\n",
       "       [ 28,  29, 431]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "bag_cm_true = contingency_matrix(bag2.predict(X2_test), y2_test)\n",
    "bag_cm_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=bag_cm_true,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True,\n",
    "                                colorbar=True,\n",
    "                                figsize=(3, 3))\n",
    "plt.savefig(\"bag_cm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McNemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Validation Accuracy: 1.0000\n",
      "Test Accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest2 = RandomForestClassifier(n_estimators=100,\n",
    "                                random_state=123)\n",
    "\n",
    "forest2.fit(X2_train, y2_train)\n",
    "    \n",
    "print(\"Training Accuracy: %0.4f\" % forest2.score(X2_train, y2_train))\n",
    "print(\"Validation Accuracy: %0.4f\" % forest2.score(X2_valid, y2_valid))\n",
    "print(\"Test Accuracy: %0.4f\" % forest2.score(X2_test, y2_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1277   15]\n",
      " [  21   55]]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import mcnemar_table\n",
    "\n",
    "# The correct target (class) labels\n",
    "y_target = y2_test\n",
    "\n",
    "# Class labels predicted by model 1\n",
    "y_forest = forest2.predict(X2_test)\n",
    "\n",
    "# Class labels predicted by model 2\n",
    "y_xgb = search2.best_estimator_.predict(X2_test)\n",
    "\n",
    "tb = mcnemar_table(y_target=y_target, \n",
    "                   y_model1=y_forest, \n",
    "                   y_model2=y_xgb)\n",
    "\n",
    "print(tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-squared: 0.6944444444444444\n",
      "p-value: 0.40465676192728617\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2, p = mcnemar(ary=tb, corrected=True)\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
