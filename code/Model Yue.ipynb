{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape: (4559, 512)\n",
      "X2.shape: (4559, 30000)\n",
      "y1.shape: (4559,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "X1 = pd.read_csv('../data/features.csv', header=None).values\n",
    "X2 = pd.read_csv('../data/raw_images.csv', header=None).values\n",
    "y1 = pd.read_csv('../data/labels.csv', header=None).values.ravel().astype(int)\n",
    "\n",
    "print('X1.shape:', X1.shape)\n",
    "print('X2.shape:', X2.shape)\n",
    "print('y1.shape:', y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 3191 639 1368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = \\\n",
    "    train_test_split(X1, y1, test_size=0.3, random_state=123, shuffle=True, stratify=y1)\n",
    "\n",
    "X1_train_sub, X1_valid, y1_train_sub, y1_valid = \\\n",
    "    train_test_split(X1_train, y1_train, test_size=0.2, random_state=123, stratify=y1_train)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y1_train.shape[0], y1_valid.shape[0], y1_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Valid/Test sizes: 3191 639 1368\n"
     ]
    }
   ],
   "source": [
    "X2_train, X2_test, y1_train, y1_test = \\\n",
    "    train_test_split(X2, y1, test_size=0.3, random_state=123, shuffle=True, stratify=y1)\n",
    "\n",
    "X2_train_sub, X2_valid, y1_train_sub, y1_valid = \\\n",
    "    train_test_split(X2_train, y1_train, test_size=0.2, random_state=123, stratify=y1_train)\n",
    "\n",
    "print('Train/Valid/Test sizes:', y1_train.shape[0], y1_valid.shape[0], y1_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   2.8s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   2.7s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   2.8s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   3.1s\n",
      "[CV] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7; total time=   3.0s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.2s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.3s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.3s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.2s\n",
      "[CV] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.1s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.2s\n",
      "[CV] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7; total time=   1.4s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.4s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.1s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.8s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.6s\n",
      "[CV] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8; total time=   3.7s\n",
      "[22:49:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.4s\n",
      "[22:50:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.4s\n",
      "[22:50:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.3s\n",
      "[22:50:03] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.3s\n",
      "[22:50:05] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0; total time=   1.3s\n",
      "[22:50:06] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.3s\n",
      "[22:50:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.4s\n",
      "[22:50:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.4s\n",
      "[22:50:10] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.4s\n",
      "[22:50:12] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9; total time=   1.3s\n",
      "[22:50:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.2s\n",
      "[22:50:15] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.3s\n",
      "[22:50:17] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.3s\n",
      "[22:50:20] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.2s\n",
      "[22:50:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9; total time=   2.3s\n",
      "[22:50:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.3s\n",
      "[22:50:30] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7; total time=   1.4s\n",
      "[22:50:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:34] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9; total time=   1.4s\n",
      "[22:50:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:38] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.1s\n",
      "[22:50:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9; total time=   0.2s\n",
      "[22:50:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[22:50:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[22:50:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.2s\n",
      "[22:50:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[22:50:48] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0; total time=   2.3s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  17.9s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  18.1s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  16.9s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  19.0s\n",
      "[CV] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0; total time=  17.1s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   5.0s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   5.3s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   4.7s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   4.6s\n",
      "[CV] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7; total time=   5.1s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  11.7s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  12.4s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  12.2s\n",
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  11.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0; total time=  11.6s\n",
      "[22:53:43] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.3s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.3s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.2s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.2s\n",
      "[22:53:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7; total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9197712923307872"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy.stats\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(random_state=123, use_label_encoder=False)\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[30, 50, 100, 300, 500],\n",
    "    'min_child_weight':[4,5], \n",
    "    \"reg_lambda\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    \"alpha\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "search1 = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search1.fit(X1_train, y1_train)\n",
    "\n",
    "search1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.6917018087001772,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bytree': 0.7,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'rmse',\n",
       " 'gamma': 0.3,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 100,\n",
       " 'objective': 'reg:tweedie',\n",
       " 'reg_lambda': 0.029423743551983135,\n",
       " 'subsample': 0.7}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  99.94%\n",
      "Test Accuracy:  91.74%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search1.best_estimator_.score(X1_train, y1_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search1.best_estimator_.score(X1_test, y1_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9170036919863896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, search1.best_estimator_.predict(X1_test), average='weighted')}\")\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV 1/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 1/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.930 total time= 3.3min\n",
      "[CV 2/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 2/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.936 total time= 3.0min\n",
      "[CV 3/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 3/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.951 total time= 3.0min\n",
      "[CV 4/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 4/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.937 total time= 3.0min\n",
      "[CV 5/5; 1/15] START alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7\n",
      "[CV 5/5; 1/15] END alpha=0.6964691955978617, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=100, objective=reg:tweedie, reg_lambda=0.7800277719120792, subsample=0.7;, score=0.953 total time= 3.0min\n",
      "[CV 1/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 1/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.933 total time= 1.1min\n",
      "[CV 2/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 2/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.937 total time= 1.1min\n",
      "[CV 3/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 3/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.945 total time= 1.1min\n",
      "[CV 4/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 4/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.926 total time= 1.1min\n",
      "[CV 5/5; 2/15] START alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0\n",
      "[CV 5/5; 2/15] END alpha=0.6848297485848633, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=5, n_estimators=50, objective=reg:tweedie, reg_lambda=0.24475928695391985, subsample=1.0;, score=0.953 total time= 1.1min\n",
      "[CV 1/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 1/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.933 total time= 1.2min\n",
      "[CV 2/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 2/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.937 total time= 1.2min\n",
      "[CV 3/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 3/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.950 total time= 1.2min\n",
      "[CV 4/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 4/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.931 total time= 1.2min\n",
      "[CV 5/5; 3/15] START alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7\n",
      "[CV 5/5; 3/15] END alpha=0.3980442653304314, booster=gbtree, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=4, min_child_weight=4, n_estimators=30, objective=reg:tweedie, reg_lambda=0.8494318040777896, subsample=0.7;, score=0.959 total time= 1.2min\n",
      "[CV 1/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 1/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.937 total time= 2.9min\n",
      "[CV 2/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.937 total time= 2.8min\n",
      "[CV 3/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 3/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.948 total time= 2.9min\n",
      "[CV 4/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 4/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.928 total time= 2.8min\n",
      "[CV 5/5; 4/15] START alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8\n",
      "[CV 5/5; 4/15] END alpha=0.7402964007347881, booster=gbtree, colsample_bytree=1.0, eta=0.5, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=4, n_estimators=50, objective=reg:squarederror, reg_lambda=0.6309761338544878, subsample=0.8;, score=0.950 total time= 3.0min\n",
      "[CV 1/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:34:09] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.928 total time= 2.3min\n",
      "[CV 2/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:36:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.915 total time= 2.2min\n",
      "[CV 3/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:38:39] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.936 total time= 2.1min\n",
      "[CV 4/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:40:42] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.923 total time= 2.2min\n",
      "[CV 5/5; 5/15] START alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0\n",
      "[00:42:53] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 5/15] END alpha=0.7770044488897805, booster=gblinear, colsample_bytree=0.8, eta=0.5, eval_metric=rmse, gamma=0.5, max_depth=4, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.8933891731171348, subsample=1.0;, score=0.931 total time= 2.2min\n",
      "[CV 1/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:45:06] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.942 total time= 2.5min\n",
      "[CV 2/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:47:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.925 total time= 2.5min\n",
      "[CV 3/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:50:07] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.940 total time= 2.4min\n",
      "[CV 4/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:52:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.928 total time= 2.4min\n",
      "[CV 5/5; 6/15] START alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9\n",
      "[00:54:57] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 6/15] END alpha=0.5018366858843366, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=7, min_child_weight=5, n_estimators=300, objective=reg:squarederror, reg_lambda=0.2504553753965067, subsample=0.9;, score=0.931 total time= 2.4min\n",
      "[CV 1/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[00:57:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.944 total time= 4.6min\n",
      "[CV 2/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:01:55] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.925 total time= 4.6min\n",
      "[CV 3/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:06:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.936 total time= 4.6min\n",
      "[CV 4/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:11:12] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.929 total time= 4.6min\n",
      "[CV 5/5; 7/15] START alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9\n",
      "[01:15:46] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 7/15] END alpha=0.4954917976836641, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=2, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.797728418895881, subsample=0.9;, score=0.929 total time= 4.5min\n",
      "[CV 1/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:20:16] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.934 total time= 2.2min\n",
      "[CV 2/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:22:24] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.918 total time= 2.2min\n",
      "[CV 3/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:24:36] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.936 total time= 2.1min\n",
      "[CV 4/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:26:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.925 total time= 2.1min\n",
      "[CV 5/5; 8/15] START alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7\n",
      "[01:28:51] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 8/15] END alpha=0.545068016466465, booster=gblinear, colsample_bytree=0.6, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=6, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5104223474780112, subsample=0.7;, score=0.931 total time= 2.1min\n",
      "[CV 1/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:31:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.950 total time= 2.8min\n",
      "[CV 2/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:33:48] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.925 total time= 2.9min\n",
      "[CV 3/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:36:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.940 total time= 2.8min\n",
      "[CV 4/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:39:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.934 total time= 2.8min\n",
      "[CV 5/5; 9/15] START alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9\n",
      "[01:42:22] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 9/15] END alpha=0.26828131771172453, booster=gblinear, colsample_bytree=0.9, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=3, min_child_weight=5, n_estimators=300, objective=reg:tweedie, reg_lambda=0.18033629310429272, subsample=0.9;, score=0.937 total time= 2.8min\n",
      "[CV 1/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.953 total time=  11.9s\n",
      "[CV 2/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.929 total time=  11.9s\n",
      "[CV 3/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.945 total time=  11.8s\n",
      "[CV 4/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:45:49] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.936 total time=  11.8s\n",
      "[CV 5/5; 10/15] START alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9\n",
      "[01:46:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 10/15] END alpha=0.21229811338998222, booster=gblinear, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=2, min_child_weight=5, n_estimators=30, objective=reg:tweedie, reg_lambda=0.15895965414472274, subsample=0.9;, score=0.947 total time=  11.8s\n",
      "[CV 1/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[01:46:13] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.931 total time= 3.5min\n",
      "[CV 2/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[01:49:44] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.920 total time= 4.3min\n",
      "[CV 3/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:54:01] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.936 total time= 3.9min\n",
      "[CV 4/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[01:57:53] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.925 total time= 3.6min\n",
      "[CV 5/5; 11/15] START alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0\n",
      "[02:01:31] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 11/15] END alpha=0.695529538770911, booster=gblinear, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.4, max_depth=3, min_child_weight=5, n_estimators=500, objective=reg:squarederror, reg_lambda=0.8549728258240765, subsample=1.0;, score=0.929 total time= 3.6min\n",
      "[CV 1/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 1/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.933 total time=11.8min\n",
      "[CV 2/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 2/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.936 total time=12.1min\n",
      "[CV 3/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 3/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.950 total time=11.7min\n",
      "[CV 4/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 4/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.939 total time=11.6min\n",
      "[CV 5/5; 12/15] START alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0\n",
      "[CV 5/5; 12/15] END alpha=0.3929444207680876, booster=gbtree, colsample_bytree=1.0, eta=0.3, eval_metric=rmse, gamma=0.5, max_depth=2, min_child_weight=4, n_estimators=500, objective=reg:squarederror, reg_lambda=0.0576480249714419, subsample=1.0;, score=0.956 total time=12.0min\n",
      "[CV 1/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 1/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.937 total time= 3.5min\n",
      "[CV 2/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 2/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.929 total time= 3.4min\n",
      "[CV 3/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 3/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.948 total time= 3.4min\n",
      "[CV 4/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 4/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.937 total time= 3.3min\n",
      "[CV 5/5; 13/15] START alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7\n",
      "[CV 5/5; 13/15] END alpha=0.6917018087001772, booster=gbtree, colsample_bytree=0.7, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=7, min_child_weight=4, n_estimators=100, objective=reg:tweedie, reg_lambda=0.029423743551983135, subsample=0.7;, score=0.959 total time= 3.5min\n",
      "[CV 1/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.936 total time= 8.1min\n",
      "[CV 2/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 2/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.933 total time= 8.3min\n",
      "[CV 3/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 3/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.950 total time= 8.4min\n",
      "[CV 4/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 4/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.934 total time= 8.0min\n",
      "[CV 5/5; 14/15] START alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0\n",
      "[CV 5/5; 14/15] END alpha=0.13089496066408074, booster=gbtree, colsample_bytree=0.8, eta=0.3, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=4, n_estimators=300, objective=reg:tweedie, reg_lambda=0.5594873855040602, subsample=1.0;, score=0.950 total time= 8.1min\n",
      "[CV 1/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:02:28] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 1/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.948 total time=  16.6s\n",
      "[CV 2/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:02:45] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 2/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.929 total time=  16.7s\n",
      "[CV 3/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:03:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 3/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.947 total time=  16.8s\n",
      "[CV 4/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:03:19] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 4/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.934 total time=  16.7s\n",
      "[CV 5/5; 15/15] START alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7\n",
      "[04:03:35] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:541: \n",
      "Parameters: { colsample_bytree, gamma, max_depth, min_child_weight, subsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[CV 5/5; 15/15] END alpha=0.31678790711837973, booster=gblinear, colsample_bytree=0.7, eta=0.5, eval_metric=rmse, gamma=0.3, max_depth=3, min_child_weight=5, n_estimators=50, objective=reg:squarederror, reg_lambda=0.578551478108833, subsample=0.7;, score=0.940 total time=  16.9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.94265432371309"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'n_estimators':[30, 50, 100, 300, 500],\n",
    "    'min_child_weight':[4,5], \n",
    "    \"reg_lambda\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    \"alpha\": scipy.stats.uniform(1e-8, 1.0),\n",
    "    'gamma':[i/10.0 for i in range(3,6)],  \n",
    "    'subsample':[i/10.0 for i in range(6,11)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,11)], \n",
    "    'max_depth': [2,3,4,6,7],\n",
    "    'objective': ['reg:squarederror', 'reg:tweedie'],\n",
    "    'booster': ['gbtree', 'gblinear'],\n",
    "    'eval_metric': ['rmse'],\n",
    "    'eta': [i/10.0 for i in range(3,6)],\n",
    "}\n",
    "\n",
    "search2 = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=10,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search2.fit(X2_train, y1_train)\n",
    "\n",
    "search2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.3929444207680876,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bytree': 1.0,\n",
       " 'eta': 0.3,\n",
       " 'eval_metric': 'rmse',\n",
       " 'gamma': 0.5,\n",
       " 'max_depth': 2,\n",
       " 'min_child_weight': 4,\n",
       " 'n_estimators': 500,\n",
       " 'objective': 'reg:squarederror',\n",
       " 'reg_lambda': 0.0576480249714419,\n",
       " 'subsample': 1.0}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  100.00%\n",
      "Test Accuracy:  94.88%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search2.best_estimator_.score(X2_train, y1_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search2.best_estimator_.score(X2_test, y1_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9487152602563024\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, search2.best_estimator_.predict(X2_test), average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[431,  10,   2],\n",
       "       [ 19, 422,   3],\n",
       "       [ 18,  18, 445]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "xgb_cm_true = contingency_matrix(search2.best_estimator_.predict(X2_test), y1_test)\n",
    "xgb_cm_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=xgb_cm_true,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True,\n",
    "                                colorbar=True,\n",
    "                                figsize=(3, 3))\n",
    "plt.savefig(\"xgb_cm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 15 candidates, totalling 150 fits\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time=   0.1s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.1s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.759635579937304"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(random_state=123, max_iter = 1000)\n",
    "\n",
    "params = {\n",
    "    \"C\": scipy.stats.expon(scale=.01),\n",
    "    \"fit_intercept\": [True, False],\n",
    "    \"warm_start\": [True,False]\n",
    "}\n",
    "\n",
    "search3 = RandomizedSearchCV(\n",
    "    estimator=lr,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=10,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search3.fit(X1_train, y1_train)\n",
    "\n",
    "search3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.03950982068814718, 'fit_intercept': True, 'warm_start': False}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  76.68%\n",
      "Test Accuracy:  78.22%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search3.best_estimator_.score(X1_train, y1_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search3.best_estimator_.score(X1_test, y1_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7691277689909498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, search3.best_estimator_.predict(X1_test), average='weighted')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.9min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.011922721434811058, fit_intercept=True, warm_start=True; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.8min\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.002572840801170508, fit_intercept=True, warm_start=False; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.012710709354874424, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.4min\n",
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.03950982068814718, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.3min\n",
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.006557201934108684, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.004203422502573983, fit_intercept=False, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.005772721768030297, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.005075713502135167, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.0020149426060868045, fit_intercept=True, warm_start=True; total time= 1.7min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.7min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.007583288393287821, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.4min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.010062180612636784, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012890055033202343, fit_intercept=True, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.012817303398323033, fit_intercept=False, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.5min\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END C=0.004490857897120136, fit_intercept=False, warm_start=True; total time= 1.6min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.5min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.6min\n",
      "[CV] END C=0.0034773509004921363, fit_intercept=True, warm_start=False; total time= 1.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9288631825785784"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search4 = RandomizedSearchCV(\n",
    "    estimator=lr,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search4.fit(X2_train, y1_train)\n",
    "\n",
    "search4.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.002572840801170508, 'fit_intercept': True, 'warm_start': False}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search4.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  100.00%\n",
      "Test Accuracy:  93.20%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search4.best_estimator_.score(X2_train, y1_train)*100: 0.2f}%\") \n",
    "print(f\"Test Accuracy: {search4.best_estimator_.score(X2_test, y1_test)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.931976655005432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, search4.best_estimator_.predict(X2_test), average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[430,  17,   8],\n",
       "       [ 25, 415,  12],\n",
       "       [ 13,  18, 430]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "lr_cm_true = contingency_matrix(search4.best_estimator_.predict(X2_test), y1_test)\n",
    "lr_cm_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANcAAADBCAYAAABc8iUzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwZUlEQVR4nO2dd3xUxdeHn5OEEiCkSBCSgEjvEDpIaAlNmii+0kMR1J+i2ECqVEFQsRcUMDTFDopSQpMW6UWlhCakCARCgpgEksz7x12WhLQNu5vd4Dx+7sfde2fmfveGc2fu3DPniFIKjUZje1wcLUCjuVvRxqXR2AltXBqNndDGpdHYCW1cGo2dcHO0AI3GWlxL36dUalKOx1XSxbVKqS4FKAnQxqW5C1CpyRSr2TfH48n73ytTgHLMaOPSFH4EEHG0iixo49LcHbi4OlpBFrRxae4CBMT55ua0cWkKP4LuuTQa+yD6mUujsRu659Jo7ICINi6Nxm7oCQ2Nxh4IuOqeS6OxPYLuuTQa+6CfuTQa+6Gn4jUaO6BnC/NG3NyVFPVwtIx80bBWRUdLyBfOd3/Pnb/+OkNcXFzesrVx5Y4U9aBYjf9ztIx88euOdx0tIV+4uTrfg39uPNC8iQWltG+hRmMftG+hRmMvdM+l0dgP3XNpNHZCT8VrNHZAT8VrNPZBABcX53vmcj5FGk1+kTw2S5oQ6SIix0TkhIi8ks1xTxH5UUQOisgfIjI0rzZ1z6W5CxCrei4RcQU+ADoCUcBuEVmllPozQ7GngT+VUj1ExBc4JiLLlFLXc2pX91yauwIRyXGzgGbACaXUKZOxfAn0uq2MAjzEaLAUcBlIza1R3XNpCj8C4pKrEZURkT0Zvs9XSs3P8N0fOJfhexTQ/LY23gdWATGAB/CYUio9t5PeNcbl4iJsXzaGmAsJPPLcx0z+Xze6t61PulJcvHyVka8uJfZiAgAvDevEkF4tSUtP58U53xC+84jDdD81cjhrflmNr29Zdu07BEDowL5EHj8OQMKVK3h6ebFj1z6HacyLd9+ex+eLPkNEqFO3HvM/W0Tx4sUL7PxCnj1UnFIqNz+q7CrfnhWyM3AA6ABUAdaLyFalVGJOjd41w8Jn+rfn2Onz5u/zwjbQ7LFZtOg7m1+2/s64kV0BqFm5HI92bkSjPjPp+fSHvDPu/3DJ/a5nVwYMCuX7VT9n2he29Et27NrHjl376Nn7YXr26u0gdXkTHR3Nhx+8y/aIPew98DtpaWl8veLLAtfh4uKS42YBUUCFDN8DMHqojAwFvlMGJ4DTQM1cNeVDv9PiX9aLLq3rsOj7HeZ9V68lmz+XcC/GzfS03dvV5+u1+7h+I5W/Yi5x8lwcTetWKmjJZloHtcHb2yfbY0opvv/ma/o8lnMcdGcgNTWVpKQk4////kt5P7+CFWAaFua0WcBuoJqI3C8iRYG+GEPAjJwFggFE5F6gBnAqt0bvimHh3JcfYcI7P1CqROahyJSnezCgezMS/kmiy0jDe93f15PfDp8xl4m+EI9fWc+ClGsx27dtpey991K1ajVHS8kRf39/Rj//EtUrV8Td3Z3gkE6EdOxU4DosnLjIFqVUqog8A6wFXIGFSqk/RORJ0/GPgenA5yJyGGMYOVYpFZdbu4W+5+oaVJcLl6+y/8i5LMemfPAj1bpO4stf9vDkY22Mndn8EZw15/o3X31Jn/9z7l4rPj6en35cyZHI05w6G8O1f6/xxbKlBapBTFPxVgwLUUr9rJSqrpSqopSaadr3scmwUErFKKU6KaXqKaXqKqXy/JGF3rhaNqxM97b1OLp6KotnD6Vd0+osnDE4U5mvftnNQ8ENAYi+cIWAct7mY/5lvc0THc5Eamoqq1Z+zyN9nHt928YN4VSqdD++vr4UKVKEhx56mIidO/KuaGusfIlsDwq9cU1+bxVVu0yiZrdXGfzKIjbvPs6wiYupUtHXXKZb2/ocP2NMdqzefIhHOzeiaBE37vO7h6oVfdn9+xkHqc+ZTRvDqV69Jv4BAY6WkisVKlRk164I/v33X5RSbNq4gRo1axWsCLF6QsMu2PWZS0S6AO9gjGM/U0rNtuf5MjLj2V5Uu68s6emKs7GXeXamMYN15NTffLtuP/u/nUBqWjqjZ39FerrjxoVDB/Vn69YtXIqLo0aVioyf+CqhQ4fzzVcrePSxxxymy1KaNW9O74f70LJZI9zc3GjQIJDhI0YWuA5rnrnshSg7PXCYXEqOk8GlBOh3m0tJJlxKlFWFbZn/xQi9zN+ePNC8CXv37snVcor6VlVlHpmT4/HYTx7Zm8d7LrtgzyttiUuJRmM9TjostOeZs3Mp8b+9kIiMFJE9IrInt6TRGk1uWOlbaBfs+cxliUsJJh+v+WAMC+2oR3MXY+HL4gLFnj2XJS4l+aZ4sSKs++w5XFyEAT2ac3jlZA6vnMyAHrf7WRpULO/Nzx+PYteKcaz99Dn8y3qZj/2z510ivnyFiC9f4eu3nzDvXzx7aKbZRmtISkqiS0h70tLSWLYkjIZ1atCwTg2WLQnLtnxKSgqhA/vSoHZ12ge15K8zZzIdT0xMpHrlCrw4epR535BB/ThxItImem9q7tihLWlpaSxdHEbdWtWoW6saSxfnrHlg/8eoU7MqQa2amzUfPHCAtq1b0qhBHZoG1ufrr1aY6wwa0JcTkbbRnFuv5ciey57GZYlLSb4J7dWSlRsO4lnKnQkju9Jm0BsEDZzLhJFd8fJwz1J+1vO9WbZ6F80em8Vr839h2qie5mNJKTdo0Xc2LfrO5tHRn5j3z/96Ky+EhlgrFYAlYYvo+VBvEhISmD1zOhu37mTTtghmz5xOfHx8lvKLP1+Il5c3B/88ztOjnmPyxMzr9mZMnUzr1m0y7Xt8xJO8/eZcm+gFCFu0kF4PPUxCQgIzZ0zl1+2/sXXHLmbOmJqt5s8XLsDby5s/jp5g1HPPM2H8WABKlCjBgkWL2XfwD1auXsOYF0dz5coVAEY+8RRvvZHzJER++U89cymlUoGbLiVHgK+UUn9Y227fB5vw4+ZDdGxViw0RR4lP/JcrV5PYEHGUTg/UzlK+ZuXybP7tGABbdh+ne7t6eZ5j+76TdGheA1cbzKyt+HI53br3ZMP6tbQPDsHHxwdvb2/aB4cQvm5NlvKrf1xJ/4HGS/CHHu7D5k0bzX6R+/ft5cKF83QI6ZipTqvWQWzeuIHU1FyXF1nMl18so0fPXqxft5bg4I5mzcHBHVm3Nqvmn35cyYBBoQA8/EgfNm/cgFKKatWrU7Wa4brl5+eHr29Z4i5eBOCB1kFs3BhuM83/uZfI2bmUWEMRN1cq+ZfhbOxl/Hy9iDp/6y4afeEKfr5eWeocPh5t9s7o1aEBpUu54+NZEoDiRd3YtmwMW8JepEe7+hl1c/JcHPWrZ5l/yRfXr1/nzOlT3FepEjExMQQE3Bol+/sHEBOTdZScsZybmxuepT25dOkS6enpjB/7MjNey3q3d3FxoXKVKhw+dNAqvVk1RxNQIYPmgABiYqKz0XyrnJubG6U9Dc0Z2b1rF9dvXKdylSpmzVWqVOXQQes1O+tsYaFy3C3jXYqEq/8C2UfSUlnnSxg373vmjX2UgT2bs33fCaLPx5OalgZA9QcnE3sxgUr+97Bm/rP8fiKG01GGL+bFy1cp7+uZrc+ipVyKi8PT08vQls37xOyeB3Iq9+knH9GpS9dM/9gz4utbltjYGAJpfMd6AeLi4vD0so3mm8TGxjJ86CA+XRCW6R/7Tc1YqdnwLXS+CY1CZVxJydcpXqwIYPRUQY1veYv7l/Vi696sD8ixFxPo+9JnAJR0L8pDwQ1J/CfZfAzgTPQlft0TScOaAWbjKl6sCEkpN6zSW9zdnZRk41z+/v5s/XWL+Vh0dBRBbdpmqePv709U1Dn8AwJITU0lITEBHx8fdkXsZMf2bXz2yUf8c+0fbly/TslSpZg2YxYAySnJuBfP+syZX9zd3Uk2aw5g65bNtzRHRRHUtl02mgOIOneOAJPmxARDMxgTMA/37MarU2fQvEWLTPWSU5Jxd7deMzhl2MLC5Vt45WoSri4uFCvqxvodRwhpWRMvD3e8PNwJaVmT9Tuyrii+x6uk+S768rDOhK2MAMDLw52iRdzMZVo2rMyRU3+b61WtWJYjJ2Ot0uvt7U1aWhrJyckEd+zMxvD1xMfHEx8fz8bw9QR37JylzoPde7J86WIAfvjuG9q2a4+IsCBsKUdOnOGP46eYOWsO/QYMMhsWwInISGrVrmOV3ts1d+zUmfDwdWbN4eHr6Ngpq+Zu3XuaZz+/+/Yb2rbvgIhw/fp1HuvTm/4DB/NIn0ez1Dtx/LhNNBvDQslxcxSFqucCCI84QqvAKmz67RizPl3DtqVjAHht/hriE40h46SnurHvz7Os3nKYNk2qMW1UT5SCbftOMHrWV4CxIvm9Cf1IV+m4iAtvLFrPUZNxlfXxIDnlOn/H5biC22I6hHRk5/ZttA8OYcy4CbR7wHhlMHb8RPPdfcbUVwls3Jhu3XsyeMgwRgwbTIPa1fH28WHR4uV5nuPC+fO4u7tTrnx5q/UChIR0Ysf2bXQIDmHc+Em0btkUgPETJps1T5symUaNm9C9R0+GDBvOsCGDqFOzKt7ePixZZvhxfvv1V2zb+iuXL11i6eLPAZi/4HMaNGzI+fPnKe7uTnkbaDbiFjpf12U338I7wRLfwgY1Anh2YAeGT1psNx2jBrQn8VoyYT/szLNsXr6FBw/s5/135vHpIvvpff/dt/Hw8CB06PA8y1riW3hg/37effstFoYtsYW8bHn37XmULl2aIcNy12yJb6F7+eqqyvAPcjz+x8xODvEtLHQ918FjUWzZcxwXF7GbN/uVq0ksX73LJm01aBhIUNt2pKWl4WqnjPOenp70GzDIZu01DAykbbv2dtXs5eVF/4E20izO+cxV6HouZ0N7xdsXS3quEn41VLURH+Z4/NC0EN1zaTR3ijM+c2nj0hR+nHRYqI1LU+hx1tlCbVyauwJnXOavjUtT+BHdc2k0dkHQz1wajZ3QjrsajX1w0mFh4XqjqNFkgzEstG6Zf15pW01l2onIAVPa1i3ZlcmI7rk0dwXW9FyWpG0VES/gQ6CLUuqsiJTNq12nMq4GNSuyads7jpaRL3zbZnuTc1ou/fq6oyXkC0ud86ycijfH2DS1dTPGZsYAtv0x8nOdBVBKXcir0RyNS0Sucuu33VSuTJ+VUqp0fn+BRmMPRPKc0LBF2tbqQBER2YyRtvUdpVSuSx1yNC6llEduFTUaZyKPjssWaVvdMOIRBAPuwE4RiVBKHc+pUYuGhSLSGqimlFokImUAD6XUaUvqajQFgat1s4WWxNiMwjDSa8A1EfkVaICRDyFb8pwtFJFXgbHAONOuokDBZjfTaHJBxOrZQktibK4EgkTETURKYAwbc81Ub0nP1RsIBPaBkWFPRPSQUeNUWNNzWZK2VSl1RETWAIeAdIyUWL/n1q4lxnVdKaVERAGISMk7/hUajR0QwMVK/yel1M/Az7ft+/i273MBi0MbW/IS+SsR+QTwEpERQDjwqaUn0GgKAhfJeXMUefZcSqk3RKQjkIgxHTlZKbXe7so0GkvJeyreIVj6EvkwxvSjMn3WaJwGWwwL7YEls4WPA7uAh4E+QISIDLO3MI0mPxTWoKAvA4FKqUsAInIPsANYaE9hGo2liJPG0LBkQiMKuJrh+1Uyu4o4DVFR5+jRNZjmjerSskl9Pv7ACHs2e+ZUaletSFCLxgS1aMy6NT/n0ZL9cXERdoY9x7dvDAXg4Q712Lv8Ba7tmE2jmgHmchXLe3N580wiFo8mYvFo3h3zsKMkm3ly5DDuC7iXJoG30jGNf+VlAuvVolnjBvR99GFzHq6CwlUkx81R5OZb+ILpYzTwm4isxHjm6oUxTHQ63FzdmPHaXBoENuLq1au0b92Mdh2MJHZPPfMco0a/6GCFt3jmsdYcO3MBj5LFAfjj1Hn6vrKE91/Jajynoi/RYvDbBawwZwYOGsITTz3DiGGh5n0dgjsybcYs3NzcmDh+LG/MmcWM1wrGSViw2kPDLuTWc3mYtpPAD9zytVoJWJehwE6UK1+eBoGNAPDw8KB6jZrEZpNPytH4+3rSpVVNFq26dY86duYCkWcvOlCV5bQOaoOPt0+mfSEdO+HmZtyrmzVvQXR0AV53J03bmpvj7tSCFGJrzv51hkMHD9C4aXN+i9jBp598yJfLlxLYqDEzZs3Fy9vbYdrmPt+DCe//TKmSxSwqX8nPh51hz3H1WgpTP1nD9oNn7CvQShZ/vohHHi3YyMnOOBVvyWyhr4jMFZGfRWTjza0gxN0p//zzD4P7/x+z5rxF6dKlGfb4k+z//ThbI/Zyb7lyTBz3ssO0dX2gFhfi/2H/Mcvu7H/HJVK912u0DH2Hse/8yOfT+uNRwjKjdARzZs/Ezc2Nvv0GFNg5jal453uJbMmExjLgKHA/MBU4g+Ho6JTcuHGD0P6P8uhj/ejRqzcAZe+9F1dXV1xcXAgd+jh79zhOfsv699E9qDZHv3+FxdMH0K5JFRZO6Ztj+es30rhsSo20/1g0p6IvUa2ib0HJzRdLl4Txy8+rWRi2tMCHYy4iOW6OwpKp+HuUUgtE5Dml1BZgiyXxAxyBUopRT42geo1aPP3s8+b9f8fGmnNX/bTqB2rVsUHCtTtk8kdrmPyRkbQ7qFFlRvdvy7ApX+ZYvoxXSS4n/kt6uqKSnw9VA8pwOuZSjuUdxbq1a5j3xhzWhG+mRIkSBXpuEed8iWyJcd3MXRorIt0w1rkE5FIeABFZCHQHLiil6t65RMuJ2LmdFV8spXadegS1MPLsTpoynW+/XsHhQwcRESredx/z3v2oIOTki55t6/DWi70o41WK794ayqHjMfQcvYDWgfczaUQnUtPSSUtXjJrzHfGJSQ7VGjqoP1t/3cyluDiqVa7AxElTeGPObFKup9DjwU4ANGvWnHc/+DiPlmyHMz5z5ZlCSES6A1sxFpO9B5QGpiqlbl/vcnu9NsA/wGJLjSuwURO1adtvlhR1Gsp3GJd3ISeisMXQaN2yKfvySCFUtkpd9cicr3I8/nGfOs6ZQkgp9ZPpYwLQ3tKGlVK/ikilO9Sl0ViOk3po5PYS+T1yCb6jlHrWFgJEZCQwEiCgQkVbNKn5D+JIT4ycyK3n2pPLMZthisIzH4xhYUGcU3N3cTMoqLOR41S8Uiost60gRWYkKSmJbp2NfL1fLF1M4/o1aVy/Jl8szT7KVUpKCsMG96NRvRqEtG3J2b/OmI+dO3eWh3t0oXmjurRoXM98bFhof06eiLSJ3uLF3Fj34ZO4uAgDHmzM4a/HcPjrMQx4sHG25SuW8+Ln90awa+nzrP3wCfx9PQGoX608mz99mr3LX2DX0ufpE9LAXGfx9P5UqVDGJnrBuMadQ4w8zkuXhFG/dnXq167O0iXZ/9lTUlIYPKAv9WpVo23rFvx15gwAZ//6iwdaNKFF00CaNKzLZ/NvTXCEDuzHiUjbXGMAN5ecN0dR6MJZL128iB49e5OYkMDrs6YTvnkHG7bs5PVZ07kSH5+l/JKwhXh6ebPv8DGeemY0UybdmoB4asQQRo1+kd/2/U74lp2U8TWCqA5//AnenfeGTfSGdm/Kys2H8SxVnAnDQ2gz/D2Chr3HhOEheHm4Zyk/a1R3lv2yj2YD5/HagnCm/a8LAP8m32D4tBU07v8WvUYvYM7oHniWMvwS538XwQsD29pEL8DizxfSs1dvEhISmDVjGpu3RbBl+2/MmjGN+GyucdiiBXh5eXH4SCTPPDuaSROMQKnlypdn45btROzez+ZtEbz5xuvExhhBlR4f+STz3ppjE702CFBjF+xmXCLyBbATqCEiUSIy3Bbtfr1iOQ9278mG8HW06xCCt48PXt7etOsQQvj6tVnK//LTKnOm+169H2HL5o0opTh65E9SU1NpH9wRgFKlSpnfz7R8IIjNmzaQmppqtd6+nQP5ceufdGxegw27IolPTOLK1SQ27IqkU4saWcrXvL8sm3efAGDL3pN0b2O8kztxLo6T5+IAiI1L5GL8P5TxLgXA9gOn6dC0Gq42Sia+4svldO/Ri/D1a+kQHIKPjw/e3t50CA5h/bo1Wcr/9OMqBgwynHh7P9yHzZs2oJSiaNGiFCtmeJOkpKSQnp5urvNA6yA2bbDNNQZwdcl5cxR2O7VSqp9SqrxSqohSKkAptcDaNq9fv85fp09T8b5KxMZEExBw63Wbv79/tk66MTEx+AcYIenc3NwoXdqTy5cucfJEJJ6eXgzq14c2LZswafwY0tLSAHBxcaFy5Sr8fvigVXqLuLlSyf8ezsbG4+dbmqgLV8zHoi8k4OebNWjx4chYHmpvvLno1a4upUsWx6d05peyTWpXoGgRV05FGS+TlVKcjIqjftXyVukF4xqfPn2K+ypVIiY6moAKt8L5+QcEEJONQ25MTDQBt13jS5cMbVHnztGscQNqVKnICy+OobyfH2C6xlWqcviQddcYjGcuN5EcN0dhiW9hdRHZICK/m77XF5GJ9peWlUuX4vD08gKMf1C3k/0QIPtyqamp7NyxjemvzWHj1gj+OnOa5UtvPVOU8S1LbOztcSHzRxmvkiRcTcpRW3azN+PeW01Qo8rsDHuOoMDKRF+4QmrarTt+uXs8WPBqX56Y/nWma3Ax/hrlszHW/HIpLg4vTy9Dn6XXOJdyARUqsGvvQQ7/GcmypYs5f/68uYxv2bLmYaK13Fwwmd3mKCzpuT7FCAh6A0ApdQgjaGKB417cneTkZAD8/AOIiooyH4uOjqZceb8sdfz8/ImOMtZ2pqamkpiYgLePD37+/tRv0JBK91fGzc2NB7v34uCB/eZ6KSnJuBfP+kyUH5JSblC8mDEhG30hgYCyXuZj/mU9ib2YmKVObFwifV9ZQsvQd3j1Y2MIlnjN+M0eJYrx3VvDmPrJGnb9cTZTveJF3UhKuZGlvfxS3N2d5BTjfP4BAUSdu7UuNjoqytzzZMT4W2S+xj4+mZeklPfzo1btOuzYvtW8LyU5meLu1l1jMAzZ1SXnzVFYYlwllFK3L460zUA5n3h5e5OWlkZycjLBIZ3YtGE9V+LjuRIfz6YN6wkO6ZSlTpduPfhi2RIAVn7/LW3atkdEaNS4KVfirxB30VhDtXXLJmrUrGWudyIykpq1rPNBvHI1CVcXF4oVdWP9b8cIaV4dLw93vDzcCWlenfW/HctS5x7PEua7/suh7Qn70XgjUsTNlRWvD2b5z3v5bmPWGEFVK5ThyKnzWfbnF+8M1zikY2c2hK8nPj6e+Ph4NoSvJ6Rj5yx1unXvwTLTTOL3331D23YdEBGio6JISjJ67vj4eCJ2bKda9VvPmZGRx6lV2zZ+ns7oFW+Jb2GciFTBNIoRkT44cLFkh+COROzYRrsOIbw8dgId2rQAYMwrE/E23S1fm/4qDRs14cFuPRgUOownHw+lUb0aeHt7syBsOQCurq5Mf+11enXrhFKKhoGNCB36OAAXzp/H3b242dnXGsJ/O06rBpXYtPsEsxaGs23hKEPjgnCzj+CkEZ3YdzSK1Vv/pE2jKkz7X1eUUmw7cJrRc78H4JGQ+rQOrIyPZ0kGdjM8eUZOX8GhyFjK+pQiOeUGf1+6mr2IfBIc0pEd27fRITiEseMn0qZVMwBemTDJ3CNNnzqZRo2a0K1HT0KHDufxoYOpV6sa3j4+hC35AoCjR48wbuxLiAhKKZ57/kXq1jVCA5w/fx53d3fK2+AaO+tKZEt8CytjvORtBcQDp4GBSqkzthZjiW/hoQP7+eC9t/lkgf1etX343tt4lC7NoNC8g1zl5VvYoLofz/YLYvjUFbaSl4VRfYNIvJZM2I95L6WxxLfwwIH9vPfOPBYsyjVDjlW89848SpcuTejQ3CeRLfEt9K9RT/3vw+9zPD4xpJpDfAvzHBYqpU4ppUIAX6CmUqq1PQzLUuo3DCSoTTvzzJ498PT0ot+AwTZp6+DxGLbsPWlXr+0rV5NY+vNem7XXsGEgbdra+Rp7eZmn761FsD5AjSVpW03lmopImmkElyt5DgtFZPJt3wFQSk2zQLNdGBg61K7tDxg8xKbtLf7Jvp5kS1bbvv3QIfYNTTnYxn9Da4aFlqRtzVDudYyEDXliyYTGtQxbGtAVqGSxco3Gzthgmb85batS6jpwM23r7YwCvgXyTNkKli05eTPjdxF5g6y5izQaxyF59lxWp20VEX+MdFodgKaWyLqThOMlgMp3UE+jsQs3e65csEXa1reBsUqpNEv9FS155jqc4USuGBMbDnve0miyYnVkXUvStjYBvjQZVhngQRFJVUr9kFOjlvRc3TN8TgXOK6Uc8hJZo8kOYz2XVU2Y07ZiRJjuC/TPWEApdb/5fCKfAz/lZliQh3GJiAuwuqACzGg0d4SAm53Ttt5Ju7kal1IqXUQOikhFpdTZ3MpqNI7CFh4alqRtzbB/iCVtWjIsLA/8ISK7MKbjb56gpyUn0GgKAidc5W+RcRXqmPGaux+Rwheg5iYPKqXGZtwhIq8DNo+6KwJFHRn04A64uGW2oyXki3taPZ93ISci5ahlqeCcz7Qs89DomM2+rrYWotHcKbbwLbQHucUtfAr4H1BZRA5lOOQBbLe3MI0mPzjhqDDXYeFy4BdgFpDRS/iqUuqyXVVpNPlArH+JbBdyS36XgBHCul/BydFo7ozCmuVEo3FuxDkj7mrj0hR6bk5oOBvauDR3Bc5nWtq4NHcBuufSaOyIE9qWNi7N3YBjE4vnhDYuTaGnMPsWajROjxPaVuHLz5UXT44cxn0B99IksJ5537Qpk2jWuAEtmgbS48HONgv+bwueGjmc+yuUo1mj+uZ9hw4eoH2bVrRq1og2rZqxZ/ft0cQdg4uLsHPZS3w7bwQAk5/syq4vxhCx7GV+fP9Jype5lQjipSEh/P79BA5+O56QFjXtqstZfQvvOuMaOGgIP/z4S6Z9o194mV17DxKxez9dH+zGrJnOEwJkwKBQvl+VaY0ek8aPZdyESezYtY8Jk6cwaXyOMSoLlGf6teXY6Vvx6Oct2UizfnNoMWAuv2z9k3EjjDjyNe+/l0c7BdLo/2bTc9THvPNKH7sGRQXDBSqn/xzFXWdcrYPa4OOdOcNG6dK37qjX/r3mVG/zWwe1wfs2vSLC1UQjA0piQoJN4qlbi39ZT7o8UJtFP0SY9129lmL+XMK9qDmTUPe29fh63X6u30jjr5jLnDwXR9M699lVn4tIjpuj+M88c02ZPIHly5ZQurQnv6zb6Gg5uTL7jXn07t6VCa+MIV2lE75pm6MlMffF3kx4dxWlShbPtH/K/x5kwINNSbiWTJcn3gcMQ/zt8BlzmegLV/Ar62k3bRaEVnMId13PlRNTps3k+MmzPNavP5989L6j5eTKgvkfM3vumxw9+Rez57zJ00+OcKierq1rc+HyP+w/GpXl2JQPf6Za96l8+ctenvy/oBzbyCvhh1Xk0ms5suf6zxjXTR57rD8/fP+do2XkyvKli+n50MMA9H7kUfbuceyERssGlenepi5HV01m8czBtGtajYXTBmYq89WavTwU3AAwJfq719t8zL+sV7aJ/mzFf25CQ0QqiMgmETkiIn+IyHP2OldenIiMNH9e/dMqatSw7+yVtZQr78e2X40oCls2baRK1WoO1TP5g5+o2m0KNXtOY/CExWzeHcmwyUupUqGMuUy3tnU5fsaY7Fj96+882imQokVcuc/Ph6oVyrD7j7/sqlFy2RyFPZ+5UoEXlVL7RMQD2Csi62/PHGFrQgf1Z+uvm7kUF0e1yhWYOGkKa9f8wvHjx3BxcaFixft49/2P7CkhXwwd1J+tW7dwKS6OGlUqMn7iq7z34SeMfel5UlNTKV68OO9+cEdh8+zOjFE9qHZfWdLTFWdjL/PsrK8BOHLqb74NP8D+r8eRmpbO6Dnfkp5ux2EhzrnkJM/kdzY7kchK4H2l1PqcyjRq3ERt25l3AjdnIr2Arp+t8H3gBUdLyBcpR74g/dr5XC2nVr1AFbZyc47Hm1fxcs7kd7ZARCoBgUCWtJEiMlJE9ojInri4iwUhR3MXIpLz5ijsblwiUgojp9FopVSWp1ql1HylVBOlVJMyZXztLUdzF2I8W/3HXiKLSBEMw1qmlHLuKTpN4SWXxHeWvv/KK22riAwQkUOmbYeINMirTXvOFgqwADiilHrLVu0mJSXROcTI17t0SRj1a1enfu3qLF2SfQLylJQUBg/oS71a1WjbugV/nTkDwNm//uKBFk1o0TSQJg3r8tn8W5MGoQP7ZZphtFZvl5D2pKWlsWxJGA3r1KBhnRosy0Vv6MC+NKhdnfZBLc16b5KYmEj1yhV4cfQo874hg/px4oRt9AIUL1aEdZ88g4uLMKBbUw5/N4HD301gQLfsc75VLOfNzx/+j11fjGHtJ8/gb3phXLGcN9uXvEjEspfZu2Isjz/Sylxn8WuDM802WocgkvOWZ+1baVu7ArWBfiJS+7Zip4G2Sqn6wHRgPnlgz57rAWAQ0EFEDpi2B61tdPHnC+nZqzcJCQnMmjGNzdsi2LL9N2bNmEZ8fHyW8mGLFuDl5cXhI5E88+xoJk0wbkrlypdn45btROzez+ZtEbz5xutmh97HRz7JvLfmWCsVgCVhi+j5kKF39szpbNy6k03bIpg9c3q2ehd/vhAvL28O/nmcp0c9x+SJmW+iM6ZOpnXrNpn2PT7iSd5+c65N9AKE9mzOyk2H8CzlzoQRnWkzZB5BoW8xYURnvDzcs5SfNboXy1bvplm/Obz26VqmPWNknYqNS6T9sLdpMWAubYbM46XQELNz7/xvtvPC4GCbabbymSvPtK1KqR1KqZt/sAiMHF65YjfjUkptU0qJUqq+Uqqhafs575q5s+LL5XTv0Yvw9WvpEByCj48P3t7edAgOYf26NVnK//TjKnPW+N4P92Hzpg0opShatCjFihUDjN4iPT3dXOeB1kFs2rCB1FTr05Ct+HI53br3ZMP6tbTPoLd9cAjh2ehd/eNK+g8cDMBDD/dh86aNZu+G/fv2cuHCeTqEZA6C3Kp1EJs32kYvQN8ujflxy+90bFmTDbuOE5/4L1euJrFh13E6taqVpXzN++9l8+7jAGzZE0n3NsaKhBupaVy/kQZAsaJumZx3t+8/RYdm1XF1tf6f4M38XLkYV5mbk2ambeRtTWSXttU/l1MOx4jpmSuFykPj+vXrnD59ivsqVSImOpqACreSAfoHBBATHZ2lTkxMNAEBRjk3NzdKl/bk0qVLAESdO0ezxg2oUaUiL7w4hvJ+fgC4uLhQuUpVDh86aLXeMzf1xsSYdQD4+wcQk83Sl4zl3Nzc8DTpTU9PZ/zYl5nxWtYe1dBbxWq9AEXcXKnkfw9nYy/j5+tJ1PlbvWv0+Sv4+Wb1ETwcGcNDHYxHkF7t61O6VHF8PEsAEHCvF7u+GEPk6im8GbaB2DhjTkspxcmoOOpX87NaM+Q5oRF3c9LMtN0+pLMkbatRUKQ9hnGNze54RgqVcV2Ki8PL0wvI3lct2/F1LuUCKlRg196DHP4zkmVLF3P+/K3lFL5ly1q97utSXBye+dSbU7lPP/mITl26ZrqhZMTXtyyxsdavUyvjVZKEf5JM5816PDt9495eSVCjKuxc9hJBjaoQff4KqanGSCDq/BWa9ZtD3YdmMLB7U8r6lDLXu3j5KuWzMdY7wcoJDUvStiIi9YHPgF5KqUt5arJMunNQ3N2d5JRkwOipos7d6smjo6LMPU9G/PwDiIoyyqWmppKYmICPT+YlHuX9/KhVuw47tm8170tJTqa4e9bni/zqTUk26fX3N+sAiI6OynYpScZyqampJJj07orYyfyPPqBO9cpMGDeGL5YtYfLEceZ6ySnJuBe3Ti9AUsoNihctYmi83UfwXi9zz5OR2LhE+o5ZRMsBb/Dqh6sBSLyWnKXMnyf/5oHAKuZ9xYsVISnlhtWac/V9ssy4zGlbRaQoRtrWVZlOIVIR+A4YpJQ6bkmjhcq4vL29SUtLIzk5mZCOndkQvp74+Hji4+PZEL6ekI6ds9Tp1r2HeWbu++++oW27DogI0VFRJCUZd+j4+HgidmynWvUa5nqRkcepVbuOzfQGd+zMxgx6N4avJzgbvQ9278nypYsB+OG7b2jbrj0iwoKwpRw5cYY/jp9i5qw59BswiGkzZpnrnYiMtFovwJWrSbi6CMWKurF+51FCmtfAy8MdLw93QprXYP3Oo1nq3ONZ0twLvzw0hLBVhq+Af1lPihczDNXLw52WDe7n+JkL5npVK/py5OTfVms2lpzcuVe8Kcf3zbStR4CvbqZtvZm6FZgM3AN8aJqc25NXu4VuPVdwSEd2bN9Gh+AQxo6fSJtWzQB4ZcIkc480fepkGjVqQrcePQkdOpzHhw6mXq1qePv4ELbkCwCOHj3CuLEvISIopXju+RepW9d4ED9//jzu7u42WaTYIaQjO7dvo31wCGPGTaDdA80BGDt+olnvjKmvEti4Md2692TwkGGMGDaYBrWr4+3jw6LFy/M8xwWT3nI2WlQZ/tsxWjWszKZdx5m1YB3bFhsuU699tpb4xH8BmPREV/YdOcvqX/+gTZOqTHu6O0optu0/yejXvwGgxv33Mnv0QyilEBHeXrqJP07GAlDWpxTJKTf4+5JtvOWt9cTIK22rUupx4PF8aSoo30JLsMS38MCB/bz3zjwWLFpsNx3vvTOP0qVLEzp0eJ5l8/ItPHhgP++/M49P7aj3/XffxsPDwyK9lvgWNqjhz7MD2jF88jJbyMuWUf3bkngtmbCVWTziMmGJb2HdBo3UN2tyXlBay6+kQ3wLC13P1bBhIG3aGi+RXV1d7XIOTy8v+g8YZJO2GjQMJMjeej096WcjvQAHj0WzZc8JXFzEbt7sV64msfznPEdWFuOMK5ELXc/lbGivePtiac/13bqce64a5XTPpdHcESI6P5dGYzecz7S0cWnuCixz0C1otHFpCj3OGlpNG5fm7kAbl0ZjH/SEhkZjJ5zPtLRxae4GxDlDq2nj0hR6bi6WdDacyrj279sbV7KYiz1Cs5YB4uzQrj0pbJrtpdei9Ch6tjAPlFJ2ia0mInsc4f5iDYVNs6P1OjKEWk44lXFpNHeKHhZqNHZA+xY6ljxjzDkhhU2zY/U6n239N4wrm2g/Tk9h0+xovXpCQ6OxC46NCZ8T2rg0hR5nfc9VqKI/5Ze8gus7GyKyUEQuiMjvjtZiKc6SQfQ/mULIUVgYXN/Z+Bzo4mgR+eRmBtFaQAvg6QK/zmJdaDV7cdcaFxYE13c2lFK/ApcdrSM/KKVilVL7TJ+vYsT9yy3Ous2xIFa8Q7ibjSu/wfU1VpJbBlG7n9sJk9/dzRMaFgfX11hPXhlE7Y2eii9YLAqur7Eep8ggqo2rQDEH1weiMYLr93espLsPe2UQzQ/79+1dW7KoS25pKh2yusCpgoLaGlMmy7cBV2ChUmqmYxXljoh8AbTDWL5xHnhVKbXAoaLyQERaA1uBw8DNDILjbZHosLBzVxuXRuNI7ubZQo3GoWjj0mjshDYujcZOaOPSaOyENi6Nxk5o47IxItJORH4yfe6Zmze+iHiJyP/u4BxTROQlS/ffVuZzEemTj3NVKkxe+s6ENi4LMXnZ5wul1Cql1OxcingB+TYuTeHgP29cpjvzUREJE5FDIvKNiJQwHTsjIpNFZBvwqIh0EpGdIrJPRL42+dPdXDd21FTu4QxtDxGR902f7xWR70XkoGlrBcwGqpiyw881lXtZRHabtEzN0NYE09q0cKCGBb9rhKmdgyLy7c3fZCJERLaKyHER6W4q7yoiczOc+wlrr+1/nf+8cZmoAcxXStUHEsncmyQrpVoD4cBEIEQp1QjYA7wgIsWBT4EeQBBQLodzvAtsUUo1ABoBfwCvACeVUg2VUi+LSCegGsZymYZAYxFpIyKNMdy3AjGMt6kFv+k7pVRT0/mOABmzkVcC2gLdgI9Nv2E4kKCUampqf4TJdUxzh9zNvoX54ZxSarvp81LgWeAN0/cVpv+3wFh0ud0Ul7wosBOoCZxWSkUCiMhSYGQ25+gADAZQSqUBCSLifVuZTqZtv+l7KQxj8wC+V0r9azrHKgt+U10RmYEx9CwFrM1w7CulVDoQKSKnTL+hE1A/w/OYp+ncxy04lyYbtHEZ3O4DlvH7NdP/BVivlOqXsaCINMym/p0iwCyl1Ce3nWP0HZzjc+AhpdRBERmC4bN4k+x+rwCjlFIZjfDmGi3NHaCHhQYVRaSl6XM/ILvU8BHAAyJSFUBESohIdeAocL+IVMlQPzs2AE+Z6rqKSGngKkavdJO1wLAMz3L+IlIW+BXoLSLuIuKBMQTNCw8g1rQcZMBtxx4VEReT5srAMdO5nzKVR0Sqi0hJC86jyQFtXAZHgFAROQT4AB/dXkApdREYAnxhKhcB1FRKJWMMA1ebJjRySiTxHNBeRA4De4E6SqlLGMPM30VkrlJqHbAc2Gkq9w3gYVpGvwI4gLFuaqsFv2kSxorg9Rg3gIwcA7YAvwBPmn7DZ8CfwD7T1Psn6JGNVfznveJNw56flFJ1Ha1Fc3ehey6Nxk7853sujcZe6J5Lo7ET2rg0GjuhjUujsRPauDQaO6GNS6OxE/8PAzpIyZuKVdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=lr_cm_true,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True,\n",
    "                                colorbar=True,\n",
    "                                figsize=(3, 3))\n",
    "plt.savefig(\"lr_cm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree + Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=4; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=9, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.4s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=gini, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=None, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=11, min_samples_split=4; total time=   0.3s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=9, min_samples_split=4; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=3; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.3s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.2s\n",
      "[CV] END criterion=entropy, max_depth=7, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.3s\n",
      "[CV] END ..criterion=gini, max_depth=11, min_samples_split=2; total time=   0.2s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n",
      "[CV] END ...criterion=gini, max_depth=5, min_samples_split=3; total time=   0.1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8691232109282069"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "params =  {\n",
    "    'min_samples_split': [2, 3, 4],\n",
    "    'max_depth': [5, 7, 9, 11, None],\n",
    "    'criterion':['entropy', 'gini']\n",
    "}\n",
    "\n",
    "search5 = RandomizedSearchCV(\n",
    "    estimator=tree,\n",
    "    param_distributions=params,\n",
    "    n_iter=15,\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1,\n",
    "    random_state=123)\n",
    "\n",
    "search5.fit(X1_train_sub, y1_train_sub)\n",
    "\n",
    "search5.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'min_samples_split': 3, 'max_depth': 5, 'criterion': 'gini'}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  91.77%\n",
      "Valid Accuracy:  87.32%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Accuracy: {search5.best_estimator_.score(X1_train_sub, y1_train_sub)*100: 0.2f}%\") \n",
    "print(f\"Valid Accuracy: {search5.best_estimator_.score(X1_valid, y1_valid)*100: 0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 93.06%\n",
      "Valid Accuracy: 88.58%\n",
      "Test Accuracy: 89.18%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag1 = BaggingClassifier(base_estimator=search5.best_estimator_, \n",
    "                        n_estimators=150, \n",
    "                        oob_score=True, \n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False, \n",
    "                        n_jobs=1, \n",
    "                        random_state=123)\n",
    "\n",
    "bag1.fit(X1_train_sub, y1_train_sub)\n",
    "print(f\"Train Accuracy: {bag1.score(X1_train_sub, y1_train_sub)*100:0.2f}%\")\n",
    "print(f\"Valid Accuracy: {bag1.score(X1_valid, y1_valid)*100:0.2f}%\")\n",
    "print(f\"Test Accuracy: {bag1.score(X1_test, y1_test)*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8912916961773778\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, bag1.predict(X1_test), average='weighted')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "search6 = DecisionTreeClassifier(max_depth=18, \n",
    "                                 min_impurity_decrease=0.017492913234125385,\n",
    "                                 min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 90.99%\n",
      "Valid Accuracy: 90.30%\n",
      "Test Accuracy: 90.20%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag2 = BaggingClassifier(base_estimator=search6, \n",
    "                        n_estimators=50, \n",
    "                        oob_score=True, \n",
    "                        bootstrap=True,\n",
    "                        bootstrap_features=False, \n",
    "                        n_jobs=1, \n",
    "                        random_state=123)\n",
    "\n",
    "bag2.fit(X2_train_sub, y1_train_sub)\n",
    "print(f\"Train Accuracy: {bag2.score(X2_train_sub, y1_train_sub)*100:0.2f}%\")\n",
    "print(f\"Valid Accuracy: {bag2.score(X2_valid, y1_valid)*100:0.2f}%\")\n",
    "print(f\"Test Accuracy: {bag2.score(X2_test, y1_test)*100:0.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.9018573316204965\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "print(f\"F1 score: {f1_score(y1_test, bag2.predict(X2_test), average='weighted')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[414,  25,   7],\n",
       "       [ 23, 390,  13],\n",
       "       [ 31,  35, 430]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "\n",
    "bag_cm_true = contingency_matrix(bag2.predict(X2_test), y1_test)\n",
    "bag_cm_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 216x216 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=bag_cm_true,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=True,\n",
    "                                colorbar=True,\n",
    "                                figsize=(3, 3))\n",
    "plt.savefig(\"bag_cm.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McNemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 1.0000\n",
      "Validation Accuracy: 1.0000\n",
      "Test Accuracy: 0.9444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest2 = RandomForestClassifier(n_estimators=100,\n",
    "                                random_state=123)\n",
    "\n",
    "forest2.fit(X2_train, y1_train)\n",
    "    \n",
    "print(\"Training Accuracy: %0.4f\" % forest2.score(X2_train, y1_train))\n",
    "print(\"Validation Accuracy: %0.4f\" % forest2.score(X2_valid, y1_valid))\n",
    "print(\"Test Accuracy: %0.4f\" % forest2.score(X2_test, y1_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1277   15]\n",
      " [  21   55]]\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import mcnemar_table\n",
    "\n",
    "# The correct target (class) labels\n",
    "y_target = y1_test\n",
    "\n",
    "# Class labels predicted by model 1\n",
    "y_forest = forest2.predict(X2_test)\n",
    "\n",
    "# Class labels predicted by model 2\n",
    "y_xgb = search2.best_estimator_.predict(X2_test)\n",
    "\n",
    "tb = mcnemar_table(y_target=y_target, \n",
    "                   y_model1=y_forest, \n",
    "                   y_model2=y_xgb)\n",
    "\n",
    "print(tb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chi-squared: 0.6944444444444444\n",
      "p-value: 0.40465676192728617\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.evaluate import mcnemar\n",
    "\n",
    "chi2, p = mcnemar(ary=tb, corrected=True)\n",
    "print('chi-squared:', chi2)\n",
    "print('p-value:', p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
